{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#USC547 Lab Assignment\n",
        "\n",
        "#Assignment II – CUDA C++ Programming\n",
        "\n",
        "##Name: Tavishi Kashyap\n",
        "\n",
        "##group: 2PA1\n"
      ],
      "metadata": {
        "id": "aSQq6bv0nTbc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q1. Identify !, %, and %% used in cell in Google Colab."
      ],
      "metadata": {
        "id": "V_-Rk7xonfTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer\n",
        "\n",
        "1.   ! is used to run Linux shell (terminal) commands inside a notebook\n",
        "2.   % is used for single line magic commands in Jupyter/Colab like measuring execution time, checking directories etc (Magic commands are special built-in command in Jupyter/Colab that provides extra functionality not available in standard Python, eg file handling, running shell commands inside cell etc)\n",
        "3.   %% applies magic command to the entire cell\n",
        "\n",
        "To sum it up- These commands help in running system level operations, timing code and executing/writng non-python code inside notebook\n",
        "\n"
      ],
      "metadata": {
        "id": "gG6SAH-dnjuk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of %% command\n",
        "#-- Writes cell contet into a file named hello.cu\n",
        "%%writefile helllo.cu\n",
        "#include <stdio.h>\n",
        "__global__ void hello() {\n",
        "    printf(\"Hello GPU\\n\");\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBBS9XaBZaw1",
        "outputId": "bf12caf5-7c15-4018-f284-4bf3b766cc54"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing helllo.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Examples of !\n",
        "\n",
        "\n",
        "!pwd #--Shows present working directory\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CubPoh3YnTj-",
        "outputId": "09b2ab38-a54a-4097-b027-fe357a42b609"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls #--Lists files in the current directory"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TnamuyddZRdH",
        "outputId": "92efef02-2af3-4fc2-9e11-72585b6ca570"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "answer\t\t  file.cu    mem_separation\tptx_demo.cu  zero_fix\n",
            "answer.cu\t  helllo.cu  mem_separation.cu\tsample_data  zero_fix.cu\n",
            "debug_example.cu  hello.cu   ptx_demo\t\tsolution.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Examples for %\n",
        "%cd /content\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhkmbCSVpqQR",
        "outputId": "0b285214-8678-4ff7-ad12-a07803dfeb9f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%time x = sum(range(10_000)) #-- Measures execution time for the line\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLDlfETXGOSp",
        "outputId": "0e8880a4-8ad7-44b3-b0cf-d4c7a84f4e76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 161 µs, sys: 20 µs, total: 181 µs\n",
            "Wall time: 183 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q2. Identify all key nvidia-smi commands with multiple options"
      ],
      "metadata": {
        "id": "5PnhfdlvnTtr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer\n",
        "\n",
        "\n",
        "*   nvidia-smi\n",
        "*   nvidia-smi -L\n",
        "\n",
        "\n",
        "*   nvidia-smi -q\n",
        "*   nvidia-smi -h\n",
        "\n",
        "\n",
        "*   nvidia-smi --help\n",
        "*   nvidia-smi -l 1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "X0zhnCJ4_8ic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n",
        "#This displays overall GPU status and usage information"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcrX7tZRnT1z",
        "outputId": "a8ef2e4f-b129-4ec1-c712-df212d93124c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Jan 28 17:44:48 2026       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi -L\n",
        "#-----to check how many gpus are present ---------------\n",
        "#Lists all available gpus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGoDwnIusgTf",
        "outputId": "e07a4f4d-ef43-4e2f-b8c3-ba4c9491b096"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-686da4c4-e8fb-a24b-23a1-632fb50a1cf7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi -q\n",
        "#---Shows: Detailed gpu usage. For example: Temperature, power usage, memory details, clock speed etc\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOb1ZQc3sgW9",
        "outputId": "d9b1c462-a1b5-4038-827f-dc4e2aa69a7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==============NVSMI LOG==============\n",
            "\n",
            "Timestamp                                 : Wed Jan 28 17:52:17 2026\n",
            "Driver Version                            : 550.54.15\n",
            "CUDA Version                              : 12.4\n",
            "\n",
            "Attached GPUs                             : 1\n",
            "GPU 00000000:00:04.0\n",
            "    Product Name                          : Tesla T4\n",
            "    Product Brand                         : NVIDIA\n",
            "    Product Architecture                  : Turing\n",
            "    Display Mode                          : Enabled\n",
            "    Display Active                        : Disabled\n",
            "    Persistence Mode                      : Disabled\n",
            "    Addressing Mode                       : None\n",
            "    MIG Mode\n",
            "        Current                           : N/A\n",
            "        Pending                           : N/A\n",
            "    Accounting Mode                       : Disabled\n",
            "    Accounting Mode Buffer Size           : 4000\n",
            "    Driver Model\n",
            "        Current                           : N/A\n",
            "        Pending                           : N/A\n",
            "    Serial Number                         : 1561820005758\n",
            "    GPU UUID                              : GPU-686da4c4-e8fb-a24b-23a1-632fb50a1cf7\n",
            "    Minor Number                          : 0\n",
            "    VBIOS Version                         : 90.04.A7.00.01\n",
            "    MultiGPU Board                        : No\n",
            "    Board ID                              : 0x4\n",
            "    Board Part Number                     : 900-2G183-6300-T00\n",
            "    GPU Part Number                       : 1EB8-895-A1\n",
            "    FRU Part Number                       : N/A\n",
            "    Module ID                             : 1\n",
            "    Inforom Version\n",
            "        Image Version                     : G183.0200.00.02\n",
            "        OEM Object                        : 1.1\n",
            "        ECC Object                        : 5.0\n",
            "        Power Management Object           : N/A\n",
            "    Inforom BBX Object Flush\n",
            "        Latest Timestamp                  : N/A\n",
            "        Latest Duration                   : N/A\n",
            "    GPU Operation Mode\n",
            "        Current                           : N/A\n",
            "        Pending                           : N/A\n",
            "    GPU C2C Mode                          : N/A\n",
            "    GPU Virtualization Mode\n",
            "        Virtualization Mode               : Pass-Through\n",
            "        Host VGPU Mode                    : N/A\n",
            "        vGPU Heterogeneous Mode           : N/A\n",
            "    GPU Reset Status\n",
            "        Reset Required                    : No\n",
            "        Drain and Reset Recommended       : N/A\n",
            "    GSP Firmware Version                  : N/A\n",
            "    IBMNPU\n",
            "        Relaxed Ordering Mode             : N/A\n",
            "    PCI\n",
            "        Bus                               : 0x00\n",
            "        Device                            : 0x04\n",
            "        Domain                            : 0x0000\n",
            "        Base Classcode                    : 0x3\n",
            "        Sub Classcode                     : 0x2\n",
            "        Device Id                         : 0x1EB810DE\n",
            "        Bus Id                            : 00000000:00:04.0\n",
            "        Sub System Id                     : 0x12A210DE\n",
            "        GPU Link Info\n",
            "            PCIe Generation\n",
            "                Max                       : 3\n",
            "                Current                   : 1\n",
            "                Device Current            : 1\n",
            "                Device Max                : 3\n",
            "                Host Max                  : N/A\n",
            "            Link Width\n",
            "                Max                       : 16x\n",
            "                Current                   : 16x\n",
            "        Bridge Chip\n",
            "            Type                          : N/A\n",
            "            Firmware                      : N/A\n",
            "        Replays Since Reset               : 0\n",
            "        Replay Number Rollovers           : 0\n",
            "        Tx Throughput                     : 0 KB/s\n",
            "        Rx Throughput                     : 0 KB/s\n",
            "        Atomic Caps Inbound               : N/A\n",
            "        Atomic Caps Outbound              : N/A\n",
            "    Fan Speed                             : N/A\n",
            "    Performance State                     : P8\n",
            "    Clocks Event Reasons\n",
            "        Idle                              : Active\n",
            "        Applications Clocks Setting       : Not Active\n",
            "        SW Power Cap                      : Not Active\n",
            "        HW Slowdown                       : Not Active\n",
            "            HW Thermal Slowdown           : Not Active\n",
            "            HW Power Brake Slowdown       : Not Active\n",
            "        Sync Boost                        : Not Active\n",
            "        SW Thermal Slowdown               : Not Active\n",
            "        Display Clock Setting             : Not Active\n",
            "    Sparse Operation Mode                 : N/A\n",
            "    FB Memory Usage\n",
            "        Total                             : 15360 MiB\n",
            "        Reserved                          : 264 MiB\n",
            "        Used                              : 0 MiB\n",
            "        Free                              : 15095 MiB\n",
            "    BAR1 Memory Usage\n",
            "        Total                             : 256 MiB\n",
            "        Used                              : 2 MiB\n",
            "        Free                              : 254 MiB\n",
            "    Conf Compute Protected Memory Usage\n",
            "        Total                             : 0 MiB\n",
            "        Used                              : 0 MiB\n",
            "        Free                              : 0 MiB\n",
            "    Compute Mode                          : Default\n",
            "    Utilization\n",
            "        Gpu                               : 0 %\n",
            "        Memory                            : 0 %\n",
            "        Encoder                           : 0 %\n",
            "        Decoder                           : 0 %\n",
            "        JPEG                              : 0 %\n",
            "        OFA                               : 0 %\n",
            "    Encoder Stats\n",
            "        Active Sessions                   : 0\n",
            "        Average FPS                       : 0\n",
            "        Average Latency                   : 0\n",
            "    FBC Stats\n",
            "        Active Sessions                   : 0\n",
            "        Average FPS                       : 0\n",
            "        Average Latency                   : 0\n",
            "    ECC Mode\n",
            "        Current                           : Enabled\n",
            "        Pending                           : Enabled\n",
            "    ECC Errors\n",
            "        Volatile\n",
            "            SRAM Correctable              : 0\n",
            "            SRAM Uncorrectable            : 0\n",
            "            DRAM Correctable              : 0\n",
            "            DRAM Uncorrectable            : 0\n",
            "        Aggregate\n",
            "            SRAM Correctable              : 0\n",
            "            SRAM Uncorrectable            : 0\n",
            "            DRAM Correctable              : 0\n",
            "            DRAM Uncorrectable            : 0\n",
            "    Retired Pages\n",
            "        Single Bit ECC                    : 0\n",
            "        Double Bit ECC                    : 0\n",
            "        Pending Page Blacklist            : No\n",
            "    Remapped Rows                         : N/A\n",
            "    Temperature\n",
            "        GPU Current Temp                  : 36 C\n",
            "        GPU T.Limit Temp                  : N/A\n",
            "        GPU Shutdown Temp                 : 96 C\n",
            "        GPU Slowdown Temp                 : 93 C\n",
            "        GPU Max Operating Temp            : 85 C\n",
            "        GPU Target Temperature            : N/A\n",
            "        Memory Current Temp               : N/A\n",
            "        Memory Max Operating Temp         : N/A\n",
            "    GPU Power Readings\n",
            "        Power Draw                        : 9.86 W\n",
            "        Current Power Limit               : 70.00 W\n",
            "        Requested Power Limit             : 70.00 W\n",
            "        Default Power Limit               : 70.00 W\n",
            "        Min Power Limit                   : 60.00 W\n",
            "        Max Power Limit                   : 70.00 W\n",
            "    GPU Memory Power Readings \n",
            "        Power Draw                        : N/A\n",
            "    Module Power Readings\n",
            "        Power Draw                        : N/A\n",
            "        Current Power Limit               : N/A\n",
            "        Requested Power Limit             : N/A\n",
            "        Default Power Limit               : N/A\n",
            "        Min Power Limit                   : N/A\n",
            "        Max Power Limit                   : N/A\n",
            "    Clocks\n",
            "        Graphics                          : 300 MHz\n",
            "        SM                                : 300 MHz\n",
            "        Memory                            : 405 MHz\n",
            "        Video                             : 540 MHz\n",
            "    Applications Clocks\n",
            "        Graphics                          : 585 MHz\n",
            "        Memory                            : 5001 MHz\n",
            "    Default Applications Clocks\n",
            "        Graphics                          : 585 MHz\n",
            "        Memory                            : 5001 MHz\n",
            "    Deferred Clocks\n",
            "        Memory                            : N/A\n",
            "    Max Clocks\n",
            "        Graphics                          : 1590 MHz\n",
            "        SM                                : 1590 MHz\n",
            "        Memory                            : 5001 MHz\n",
            "        Video                             : 1470 MHz\n",
            "    Max Customer Boost Clocks\n",
            "        Graphics                          : 1590 MHz\n",
            "    Clock Policy\n",
            "        Auto Boost                        : N/A\n",
            "        Auto Boost Default                : N/A\n",
            "    Voltage\n",
            "        Graphics                          : N/A\n",
            "    Fabric\n",
            "        State                             : N/A\n",
            "        Status                            : N/A\n",
            "        CliqueId                          : N/A\n",
            "        ClusterUUID                       : N/A\n",
            "        Health\n",
            "            Bandwidth                     : N/A\n",
            "    Processes                             : None\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi --help\n",
        "# shows all supported options and flags"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6AbKWCnasgZY",
        "outputId": "1e6b2213-4088-4bb3-8cb3-76dea4ad5a33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NVIDIA System Management Interface -- v550.54.15\n",
            "\n",
            "NVSMI provides monitoring information for Tesla and select Quadro devices.\n",
            "The data is presented in either a plain text or an XML format, via stdout or a file.\n",
            "NVSMI also provides several management operations for changing the device state.\n",
            "\n",
            "Note that the functionality of NVSMI is exposed through the NVML C-based\n",
            "library. See the NVIDIA developer website for more information about NVML.\n",
            "Python wrappers to NVML are also available.  The output of NVSMI is\n",
            "not guaranteed to be backwards compatible; NVML and the bindings are backwards\n",
            "compatible.\n",
            "\n",
            "http://developer.nvidia.com/nvidia-management-library-nvml/\n",
            "http://pypi.python.org/pypi/nvidia-ml-py/\n",
            "Supported products:\n",
            "- Full Support\n",
            "    - All Tesla products, starting with the Kepler architecture\n",
            "    - All Quadro products, starting with the Kepler architecture\n",
            "    - All GRID products, starting with the Kepler architecture\n",
            "    - GeForce Titan products, starting with the Kepler architecture\n",
            "- Limited Support\n",
            "    - All Geforce products, starting with the Kepler architecture\n",
            "nvidia-smi [OPTION1 [ARG1]] [OPTION2 [ARG2]] ...\n",
            "\n",
            "    -h,   --help                Print usage information and exit.\n",
            "\n",
            "          --version             Print version information and exit.\n",
            "\n",
            "  LIST OPTIONS:\n",
            "\n",
            "    -L,   --list-gpus           Display a list of GPUs connected to the system.\n",
            "\n",
            "    -B,   --list-excluded-gpus  Display a list of excluded GPUs in the system.\n",
            "\n",
            "  SUMMARY OPTIONS:\n",
            "\n",
            "    <no arguments>              Show a summary of GPUs connected to the system.\n",
            "\n",
            "    [plus any of]\n",
            "\n",
            "    -i,   --id=                 Target a specific GPU.\n",
            "    -f,   --filename=           Log to a specified file, rather than to stdout.\n",
            "    -l,   --loop=               Probe until Ctrl+C at specified second interval.\n",
            "\n",
            "  QUERY OPTIONS:\n",
            "\n",
            "    -q,   --query               Display GPU or Unit info.\n",
            "\n",
            "    [plus any of]\n",
            "\n",
            "    -u,   --unit                Show unit, rather than GPU, attributes.\n",
            "    -i,   --id=                 Target a specific GPU or Unit.\n",
            "    -f,   --filename=           Log to a specified file, rather than to stdout.\n",
            "    -x,   --xml-format          Produce XML output.\n",
            "          --dtd                 When showing xml output, embed DTD.\n",
            "    -d,   --display=            Display only selected information: MEMORY,\n",
            "                                    UTILIZATION, ECC, TEMPERATURE, POWER, CLOCK,\n",
            "                                    COMPUTE, PIDS, PERFORMANCE, SUPPORTED_CLOCKS,\n",
            "                                    PAGE_RETIREMENT, ACCOUNTING, ENCODER_STATS,\n",
            "                                    SUPPORTED_GPU_TARGET_TEMP, VOLTAGE, FBC_STATS\n",
            "                                    ROW_REMAPPER, RESET_STATUS, GSP_FIRMWARE_VERSION\n",
            "                                Flags can be combined with comma e.g. ECC,POWER.\n",
            "                                Sampling data with max/min/avg is also returned \n",
            "                                for POWER, UTILIZATION and CLOCK display types.\n",
            "                                Doesn't work with -u or -x flags.\n",
            "    -l,   --loop=               Probe until Ctrl+C at specified second interval.\n",
            "\n",
            "    -lms, --loop-ms=            Probe until Ctrl+C at specified millisecond interval.\n",
            "\n",
            "  SELECTIVE QUERY OPTIONS:\n",
            "\n",
            "    Allows the caller to pass an explicit list of properties to query.\n",
            "\n",
            "    [one of]\n",
            "\n",
            "    --query-gpu                 Information about GPU.\n",
            "                                Call --help-query-gpu for more info.\n",
            "    --query-supported-clocks    List of supported clocks.\n",
            "                                Call --help-query-supported-clocks for more info.\n",
            "    --query-compute-apps        List of currently active compute processes.\n",
            "                                Call --help-query-compute-apps for more info.\n",
            "    --query-accounted-apps      List of accounted compute processes.\n",
            "                                Call --help-query-accounted-apps for more info.\n",
            "                                This query is not supported on vGPU host.\n",
            "    --query-retired-pages       List of device memory pages that have been retired.\n",
            "                                Call --help-query-retired-pages for more info.\n",
            "    --query-remapped-rows       Information about remapped rows.\n",
            "                                Call --help-query-remapped-rows for more info.\n",
            "\n",
            "    [mandatory]\n",
            "\n",
            "    --format=                   Comma separated list of format options:\n",
            "                                  csv - comma separated values (MANDATORY)\n",
            "                                  noheader - skip the first line with column headers\n",
            "                                  nounits - don't print units for numerical\n",
            "                                             values\n",
            "\n",
            "    [plus any of]\n",
            "\n",
            "    -i,   --id=                 Target a specific GPU or Unit.\n",
            "    -f,   --filename=           Log to a specified file, rather than to stdout.\n",
            "    -l,   --loop=               Probe until Ctrl+C at specified second interval.\n",
            "    -lms, --loop-ms=            Probe until Ctrl+C at specified millisecond interval.\n",
            "\n",
            "  DEVICE MODIFICATION OPTIONS:\n",
            "\n",
            "    [any one of]\n",
            "\n",
            "    -pm,  --persistence-mode=   Set persistence mode: 0/DISABLED, 1/ENABLED\n",
            "    -e,   --ecc-config=         Toggle ECC support: 0/DISABLED, 1/ENABLED\n",
            "    -p,   --reset-ecc-errors=   Reset ECC error counts: 0/VOLATILE, 1/AGGREGATE\n",
            "    -c,   --compute-mode=       Set MODE for compute applications:\n",
            "                                0/DEFAULT, 1/EXCLUSIVE_THREAD (DEPRECATED),\n",
            "                                2/PROHIBITED, 3/EXCLUSIVE_PROCESS\n",
            "          --gom=                Set GPU Operation Mode:\n",
            "                                    0/ALL_ON, 1/COMPUTE, 2/LOW_DP\n",
            "    -r    --gpu-reset           Trigger reset of the GPU.\n",
            "                                Can be used to reset the GPU HW state in situations\n",
            "                                that would otherwise require a machine reboot.\n",
            "                                Typically useful if a double bit ECC error has\n",
            "                                occurred.\n",
            "                                Reset operations are not guarenteed to work in\n",
            "                                all cases and should be used with caution.\n",
            "    -vm   --virt-mode=          Switch GPU Virtualization Mode:\n",
            "                                Sets GPU virtualization mode to 3/VGPU or 4/VSGA\n",
            "                                Virtualization mode of a GPU can only be set when\n",
            "                                it is running on a hypervisor.\n",
            "    -lgc  --lock-gpu-clocks=    Specifies <minGpuClock,maxGpuClock> clocks as a\n",
            "                                    pair (e.g. 1500,1500) that defines the range \n",
            "                                    of desired locked GPU clock speed in MHz.\n",
            "                                    Setting this will supercede application clocks\n",
            "                                    and take effect regardless if an app is running.\n",
            "                                    Input can also be a singular desired clock value\n",
            "                                    (e.g. <GpuClockValue>). Optionally, --mode can be\n",
            "                                    specified to indicate a special mode.\n",
            "    -m    --mode=               Specifies the mode for --locked-gpu-clocks.\n",
            "                                    Valid modes: 0, 1\n",
            "    -rgc  --reset-gpu-clocks\n",
            "                                Resets the Gpu clocks to the default values.\n",
            "    -lmc  --lock-memory-clocks=  Specifies <minMemClock,maxMemClock> clocks as a\n",
            "                                    pair (e.g. 5100,5100) that defines the range \n",
            "                                    of desired locked Memory clock speed in MHz.\n",
            "                                    Input can also be a singular desired clock value\n",
            "                                    (e.g. <MemClockValue>).\n",
            "    -rmc  --reset-memory-clocks\n",
            "                                Resets the Memory clocks to the default values.\n",
            "    -lmcd --lock-memory-clocks-deferred=\n",
            "                                    Specifies memClock clock to lock. This limit is\n",
            "                                    applied the next time GPU is initialized.\n",
            "                                    This is guaranteed by unloading and reloading the kernel module.\n",
            "                                    Requires root.\n",
            "    -rmcd --reset-memory-clocks-deferred\n",
            "                                Resets the deferred Memory clocks applied.\n",
            "    -ac   --applications-clocks= Specifies <memory,graphics> clocks as a\n",
            "                                    pair (e.g. 2000,800) that defines GPU's\n",
            "                                    speed in MHz while running applications on a GPU.\n",
            "    -rac  --reset-applications-clocks\n",
            "                                Resets the applications clocks to the default values.\n",
            "    -pl   --power-limit=        Specifies maximum power management limit in watts.\n",
            "                                Takes an optional argument --scope.\n",
            "    -sc   --scope=              Specifies the device type for --scope: 0/GPU, 1/TOTAL_MODULE (Grace Hopper Only)\n",
            "    -cc   --cuda-clocks=        Overrides or restores default CUDA clocks.\n",
            "                                In override mode, GPU clocks higher frequencies when running CUDA applications.\n",
            "                                Only on supported devices starting from the Volta series.\n",
            "                                Requires administrator privileges.\n",
            "                                0/RESTORE_DEFAULT, 1/OVERRIDE\n",
            "    -am   --accounting-mode=    Enable or disable Accounting Mode: 0/DISABLED, 1/ENABLED\n",
            "    -caa  --clear-accounted-apps\n",
            "                                Clears all the accounted PIDs in the buffer.\n",
            "          --auto-boost-default= Set the default auto boost policy to 0/DISABLED\n",
            "                                or 1/ENABLED, enforcing the change only after the\n",
            "                                last boost client has exited.\n",
            "          --auto-boost-permission=\n",
            "                                Allow non-admin/root control over auto boost mode:\n",
            "                                0/UNRESTRICTED, 1/RESTRICTED\n",
            "    -mig  --multi-instance-gpu= Enable or disable Multi Instance GPU: 0/DISABLED, 1/ENABLED\n",
            "                                Requires root.\n",
            "    -gtt  --gpu-target-temp=    Set GPU Target Temperature for a GPU in degree celsius.\n",
            "                                Requires administrator privileges\n",
            "\n",
            "   [plus optional]\n",
            "\n",
            "    -i,   --id=                 Target a specific GPU.\n",
            "    -eow, --error-on-warning    Return a non-zero error for warnings.\n",
            "\n",
            "  UNIT MODIFICATION OPTIONS:\n",
            "\n",
            "    -t,   --toggle-led=         Set Unit LED state: 0/GREEN, 1/AMBER\n",
            "\n",
            "   [plus optional]\n",
            "\n",
            "    -i,   --id=                 Target a specific Unit.\n",
            "\n",
            "  SHOW DTD OPTIONS:\n",
            "\n",
            "          --dtd                 Print device DTD and exit.\n",
            "\n",
            "     [plus optional]\n",
            "\n",
            "    -f,   --filename=           Log to a specified file, rather than to stdout.\n",
            "    -u,   --unit                Show unit, rather than device, DTD.\n",
            "\n",
            "    --debug=                    Log encrypted debug information to a specified file. \n",
            "\n",
            " Device Monitoring:\n",
            "    dmon                        Displays device stats in scrolling format.\n",
            "                                \"nvidia-smi dmon -h\" for more information.\n",
            "\n",
            "    daemon                      Runs in background and monitor devices as a daemon process.\n",
            "                                This is an experimental feature. Not supported on Windows baremetal\n",
            "                                \"nvidia-smi daemon -h\" for more information.\n",
            "\n",
            "    replay                      Used to replay/extract the persistent stats generated by daemon.\n",
            "                                This is an experimental feature.\n",
            "                                \"nvidia-smi replay -h\" for more information.\n",
            "\n",
            " Process Monitoring:\n",
            "    pmon                        Displays process stats in scrolling format.\n",
            "                                \"nvidia-smi pmon -h\" for more information.\n",
            "\n",
            " TOPOLOGY:\n",
            "    topo                        Displays device/system topology. \"nvidia-smi topo -h\" for more information.\n",
            "\n",
            " DRAIN STATES:\n",
            "    drain                       Displays/modifies GPU drain states for power idling. \"nvidia-smi drain -h\" for more information.\n",
            "\n",
            " NVLINK:\n",
            "    nvlink                      Displays device nvlink information. \"nvidia-smi nvlink -h\" for more information.\n",
            "\n",
            " C2C:\n",
            "    c2c                         Displays device C2C information. \"nvidia-smi c2c -h\" for more information.\n",
            "\n",
            " CLOCKS:\n",
            "    clocks                      Control and query clock information. \"nvidia-smi clocks -h\" for more information.\n",
            "\n",
            " ENCODER SESSIONS:\n",
            "    encodersessions             Displays device encoder sessions information. \"nvidia-smi encodersessions -h\" for more information.\n",
            "\n",
            " FBC SESSIONS:\n",
            "    fbcsessions                 Displays device FBC sessions information. \"nvidia-smi fbcsessions -h\" for more information.\n",
            "\n",
            " GRID vGPU:\n",
            "    vgpu                        Displays vGPU information. \"nvidia-smi vgpu -h\" for more information.\n",
            "\n",
            " MIG:\n",
            "    mig                         Provides controls for MIG management. \"nvidia-smi mig -h\" for more information.\n",
            "\n",
            " COMPUTE POLICY:\n",
            "    compute-policy              Control and query compute policies. \"nvidia-smi compute-policy -h\" for more information. \n",
            "\n",
            " BOOST SLIDER:\n",
            "    boost-slider                Control and query boost sliders. \"nvidia-smi boost-slider -h\" for more information. \n",
            "\n",
            " POWER HINT:    power-hint                  Estimates GPU power usage. \"nvidia-smi power-hint -h\" for more information. \n",
            "\n",
            " BASE CLOCKS:    base-clocks                 Query GPU base clocks. \"nvidia-smi base-clocks -h\" for more information. \n",
            "\n",
            " CONFIDENTIAL COMPUTE:\n",
            "    conf-compute                Control and query confidential compute. \"nvidia-smi conf-compute -h\" for more information. \n",
            "\n",
            " GPU PERFORMANCE MONITORING: \n",
            "    gpm                         Control and query GPU performance monitoring unit. \"nvidia-smi gpm -h\" for more information. \n",
            "\n",
            " PCI:\n",
            "    pci                         Display device PCI information. \"nvidia-smi pci -h\" for more information.\n",
            "\n",
            "Please see the nvidia-smi(1) manual page for more detailed information.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi -h"
      ],
      "metadata": {
        "id": "Xa339zHeEMOx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea3a9994-9f29-4923-9b34-c361423ab487"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NVIDIA System Management Interface -- v580.82.07\n",
            "\n",
            "NVSMI provides monitoring information for Tesla and select Quadro devices.\n",
            "The data is presented in either a plain text or an XML format, via stdout or a file.\n",
            "NVSMI also provides several management operations for changing the device state.\n",
            "\n",
            "Note that the functionality of NVSMI is exposed through the NVML C-based\n",
            "library. See the NVIDIA developer website for more information about NVML.\n",
            "Python wrappers to NVML are also available.  The output of NVSMI is\n",
            "not guaranteed to be backwards compatible; NVML and the bindings are backwards\n",
            "compatible.\n",
            "\n",
            "http://developer.nvidia.com/nvidia-management-library-nvml/\n",
            "http://pypi.python.org/pypi/nvidia-ml-py/\n",
            "Supported products:\n",
            "- Full Support\n",
            "    - All Tesla products, starting with the Kepler architecture\n",
            "    - All Quadro products, starting with the Kepler architecture\n",
            "    - All GRID products, starting with the Kepler architecture\n",
            "    - GeForce Titan products, starting with the Kepler architecture\n",
            "- Limited Support\n",
            "    - All Geforce products, starting with the Kepler architecture\n",
            "nvidia-smi [OPTION1 [ARG1]] [OPTION2 [ARG2]] ...\n",
            "\n",
            "    -h,   --help                Print usage information and exit.\n",
            "\n",
            "          --version             Print version information and exit.\n",
            "\n",
            "  LIST OPTIONS:\n",
            "\n",
            "    -L,   --list-gpus           Display a list of GPUs connected to the system.\n",
            "\n",
            "    -B,   --list-excluded-gpus  Display a list of excluded GPUs in the system.\n",
            "\n",
            "  SUMMARY OPTIONS:\n",
            "\n",
            "    <no arguments>              Show a summary of GPUs connected to the system.\n",
            "\n",
            "    -col, --columns             Show a summary of GPUs connected to the system in multi-column format.\n",
            "\n",
            "    [plus any of]\n",
            "\n",
            "    -i,   --id=                 Target a specific GPU.\n",
            "    -f,   --filename=           Log to a specified file, rather than to stdout.\n",
            "    -l,   --loop=               Probe until Ctrl+C at specified second interval.\n",
            "\n",
            "  QUERY OPTIONS:\n",
            "\n",
            "    -q,   --query               Display GPU or Unit info.\n",
            "\n",
            "    [plus any of]\n",
            "\n",
            "    -u,   --unit                Show unit, rather than GPU, attributes.\n",
            "    -i,   --id=                 Target a specific GPU or Unit.\n",
            "    -f,   --filename=           Log to a specified file, rather than to stdout.\n",
            "    -x,   --xml-format          Produce XML output.\n",
            "          --dtd                 When showing xml output, embed DTD.\n",
            "    -d,   --display=            Display only selected information: MEMORY,\n",
            "                                    UTILIZATION, ECC, TEMPERATURE, POWER, CLOCK,\n",
            "                                    COMPUTE, PIDS, PERFORMANCE, SUPPORTED_CLOCKS,\n",
            "                                    PAGE_RETIREMENT, ACCOUNTING, ENCODER_STATS,\n",
            "                                    SUPPORTED_GPU_TARGET_TEMP, VOLTAGE, FBC_STATS\n",
            "                                    ROW_REMAPPER, GSP_FIRMWARE_VERSION\n",
            "                                    POWER_SMOOTHING, POWER_PROFILES\n",
            "                                Flags can be combined with comma e.g. ECC,POWER.\n",
            "                                Sampling data with max/min/avg is also returned \n",
            "                                for POWER, UTILIZATION and CLOCK display types.\n",
            "                                Doesn't work with -u or -x flags.\n",
            "    -l,   --loop=               Probe until Ctrl+C at specified second interval.\n",
            "\n",
            "    -lms, --loop-ms=            Probe until Ctrl+C at specified millisecond interval.\n",
            "\n",
            "  SELECTIVE QUERY OPTIONS:\n",
            "\n",
            "    Allows the caller to pass an explicit list of properties to query.\n",
            "\n",
            "    [one of]\n",
            "\n",
            "    --query-gpu                 Information about GPU.\n",
            "                                Call --help-query-gpu for more info.\n",
            "    --query-supported-clocks    List of supported clocks.\n",
            "                                Call --help-query-supported-clocks for more info.\n",
            "    --query-compute-apps        List of currently active compute processes.\n",
            "                                Call --help-query-compute-apps for more info.\n",
            "    --query-accounted-apps      List of accounted compute processes.\n",
            "                                Call --help-query-accounted-apps for more info.\n",
            "                                This query is not supported on vGPU host.\n",
            "    --query-retired-pages       List of device memory pages that have been retired.\n",
            "                                Call --help-query-retired-pages for more info.\n",
            "    --query-remapped-rows       Information about remapped rows.\n",
            "                                Call --help-query-remapped-rows for more info.\n",
            "\n",
            "    [mandatory]\n",
            "\n",
            "    --format=                   Comma separated list of format options:\n",
            "                                  csv - comma separated values (MANDATORY)\n",
            "                                  noheader - skip the first line with column headers\n",
            "                                  nounits - don't print units for numerical\n",
            "                                             values\n",
            "\n",
            "    [plus any of]\n",
            "\n",
            "    -i,   --id=                 Target a specific GPU or Unit.\n",
            "    -f,   --filename=           Log to a specified file, rather than to stdout.\n",
            "    -l,   --loop=               Probe until Ctrl+C at specified second interval.\n",
            "    -lms, --loop-ms=            Probe until Ctrl+C at specified millisecond interval.\n",
            "\n",
            "  DEVICE MODIFICATION OPTIONS:\n",
            "\n",
            "    [any one of]\n",
            "\n",
            "    -pm,  --persistence-mode=   Set persistence mode: 0/DISABLED, 1/ENABLED\n",
            "    -e,   --ecc-config=         Toggle ECC support: 0/DISABLED, 1/ENABLED\n",
            "    -p,   --reset-ecc-errors=   Reset ECC error counts: 0/VOLATILE, 1/AGGREGATE\n",
            "    -c,   --compute-mode=       Set MODE for compute applications:\n",
            "                                0/DEFAULT, 1/EXCLUSIVE_THREAD (DEPRECATED),\n",
            "                                2/PROHIBITED, 3/EXCLUSIVE_PROCESS\n",
            "          --gom=                Set GPU Operation Mode:\n",
            "                                    0/ALL_ON, 1/COMPUTE, 2/LOW_DP\n",
            "    -r    --gpu-reset           Trigger reset of the GPU.\n",
            "                                Can be used to reset the GPU HW state in situations\n",
            "                                that would otherwise require a machine reboot.\n",
            "                                Typically useful if a double bit ECC error has\n",
            "                                occurred.\n",
            "                                Reset operations are not guaranteed to work in\n",
            "                                all cases and should be used with caution.\n",
            "                                Reset triggered without extra arguments, will be a.\n",
            "                                default Function Level Reset (FLR). To issue a\n",
            "                                Bus Reset, use -r bus.\n",
            "    -vm   --virt-mode=          Switch GPU Virtualization Mode:\n",
            "                                Sets GPU virtualization mode to 3/VGPU or 4/VSGA\n",
            "                                Virtualization mode of a GPU can only be set when\n",
            "                                it is running on a hypervisor.\n",
            "    -lgc  --lock-gpu-clocks=    Specifies <minGpuClock,maxGpuClock> clocks as a\n",
            "                                    pair (e.g. 1500,1500) that defines the range \n",
            "                                    of desired locked GPU clock speed in MHz.\n",
            "                                    Setting this will supersede application clocks\n",
            "                                    and take effect regardless if an app is running.\n",
            "                                    Input can also be a singular desired clock value\n",
            "                                    (e.g. <GpuClockValue>). Optionally, --mode can be\n",
            "                                    specified to indicate a special mode.\n",
            "    -m    --mode=               Specifies the mode for --lock-gpu-clocks.\n",
            "                                    Valid modes: 0, 1\n",
            "    -rgc  --reset-gpu-clocks\n",
            "                                Resets the GPU clocks to the default values.\n",
            "    -lmc  --lock-memory-clocks=  Specifies <minMemClock,maxMemClock> clocks as a\n",
            "                                    pair (e.g. 5100,5100) that defines the range \n",
            "                                    of desired locked Memory clock speed in MHz.\n",
            "                                    Input can also be a singular desired clock value\n",
            "                                    (e.g. <MemClockValue>).\n",
            "    -rmc  --reset-memory-clocks\n",
            "                                Resets the Memory clocks to the default values.\n",
            "    -lmcd --lock-memory-clocks-deferred=\n",
            "                                    Specifies memClock clock to lock. This limit is\n",
            "                                    applied the next time GPU is initialized.\n",
            "                                    This is guaranteed by unloading and reloading the kernel module.\n",
            "                                    Requires root.\n",
            "    -rmcd --reset-memory-clocks-deferred\n",
            "                                Resets the deferred Memory clocks applied.\n",
            "    -ac   --applications-clocks= Specifies <memory,graphics> clocks as a\n",
            "                                    pair (e.g. 2000,800) that defines GPU's\n",
            "                                    speed in MHz while running applications on a GPU.\n",
            "    -rac  --reset-applications-clocks\n",
            "                                Resets the applications clocks to the default values.\n",
            "    -pl   --power-limit=        Specifies maximum power management limit in watts.\n",
            "                                Takes an optional argument --scope.\n",
            "    -sc   --scope=              Specifies the device type for --scope: 0/GPU, 1/TOTAL_MODULE (Grace Hopper Only)\n",
            "    -cc   --cuda-clocks=        Overrides or restores default CUDA clocks.\n",
            "                                In override mode, GPU clocks higher frequencies when running CUDA applications.\n",
            "                                Only on supported devices starting from the Volta series.\n",
            "                                Requires administrator privileges.\n",
            "                                0/RESTORE_DEFAULT, 1/OVERRIDE\n",
            "    -am   --accounting-mode=    Enable or disable Accounting Mode: 0/DISABLED, 1/ENABLED\n",
            "    -caa  --clear-accounted-apps\n",
            "                                Clears all the accounted PIDs in the buffer.\n",
            "          --auto-boost-default= Set the default auto boost policy to 0/DISABLED\n",
            "                                or 1/ENABLED, enforcing the change only after the\n",
            "                                last boost client has exited.\n",
            "          --auto-boost-permission=\n",
            "                                Allow non-admin/root control over auto boost mode:\n",
            "                                0/UNRESTRICTED, 1/RESTRICTED\n",
            "    -mig  --multi-instance-gpu= Enable or disable Multi Instance GPU: 0/DISABLED, 1/ENABLED\n",
            "                                Requires root.\n",
            "    -gtt  --gpu-target-temp=    Set GPU Target Temperature for a GPU in degree celsius.\n",
            "                                Requires administrator privileges\n",
            "    -den, --dram-encryption=    Toggle DRAM Encryption support: 0/DISABLED, 1/ENABLED\n",
            "                                Requires root.\n",
            "\n",
            "   [plus optional]\n",
            "\n",
            "    -i,   --id=                 Target a specific GPU.\n",
            "    -eow, --error-on-warning    Return a non-zero error for warnings.\n",
            "\n",
            "  UNIT MODIFICATION OPTIONS:\n",
            "\n",
            "    -t,   --toggle-led=         Set Unit LED state: 0/GREEN, 1/AMBER\n",
            "\n",
            "   [plus optional]\n",
            "\n",
            "    -i,   --id=                 Target a specific Unit.\n",
            "\n",
            "  SHOW DTD OPTIONS:\n",
            "\n",
            "          --dtd                 Print device DTD and exit.\n",
            "\n",
            "     [plus optional]\n",
            "\n",
            "    -f,   --filename=           Log to a specified file, rather than to stdout.\n",
            "    -u,   --unit                Show unit, rather than device, DTD.\n",
            "\n",
            "    --debug=                    Log encrypted debug information to a specified file. \n",
            "\n",
            " Device Monitoring:\n",
            "    dmon                        Displays device stats in scrolling format.\n",
            "                                \"nvidia-smi dmon -h\" for more information.\n",
            "\n",
            "    daemon                      Runs in background and monitor devices as a daemon process.\n",
            "                                This is an experimental feature. Not supported on Windows baremetal\n",
            "                                \"nvidia-smi daemon -h\" for more information.\n",
            "\n",
            "    replay                      Used to replay/extract the persistent stats generated by daemon.\n",
            "                                This is an experimental feature.\n",
            "                                \"nvidia-smi replay -h\" for more information.\n",
            "\n",
            " Process Monitoring:\n",
            "    pmon                        Displays process stats in scrolling format.\n",
            "                                \"nvidia-smi pmon -h\" for more information.\n",
            "\n",
            " TOPOLOGY:\n",
            "    topo                        Displays device/system topology. \"nvidia-smi topo -h\" for more information.\n",
            "\n",
            " DRAIN STATES:\n",
            "    drain                       Displays/modifies GPU drain states for power idling. \"nvidia-smi drain -h\" for more information.\n",
            "\n",
            " NVLINK:\n",
            "    nvlink                      Displays device nvlink information. \"nvidia-smi nvlink -h\" for more information.\n",
            "\n",
            " C2C:\n",
            "    c2c                         Displays device C2C information. \"nvidia-smi c2c -h\" for more information.\n",
            "\n",
            " CLOCKS:\n",
            "    clocks                      Control and query clock information. \"nvidia-smi clocks -h\" for more information.\n",
            "\n",
            " ENCODER SESSIONS:\n",
            "    encodersessions             Displays device encoder sessions information. \"nvidia-smi encodersessions -h\" for more information.\n",
            "\n",
            " FBC SESSIONS:\n",
            "    fbcsessions                 Displays device FBC sessions information. \"nvidia-smi fbcsessions -h\" for more information.\n",
            "\n",
            " GRID vGPU:\n",
            "    vgpu                        Displays vGPU information. \"nvidia-smi vgpu -h\" for more information.\n",
            "\n",
            " MIG:\n",
            "    mig                         Provides controls for MIG management. \"nvidia-smi mig -h\" for more information.\n",
            "\n",
            " COMPUTE POLICY:\n",
            "    compute-policy              Control and query compute policies. \"nvidia-smi compute-policy -h\" for more information. \n",
            "\n",
            " BOOST SLIDER:\n",
            "    boost-slider                Control and query boost sliders. \"nvidia-smi boost-slider -h\" for more information. \n",
            "\n",
            " POWER HINT:    power-hint                  Estimates GPU power usage. \"nvidia-smi power-hint -h\" for more information. \n",
            "\n",
            " BASE CLOCKS:    base-clocks                 Query GPU base clocks. \"nvidia-smi base-clocks -h\" for more information. \n",
            "\n",
            " CONFIDENTIAL COMPUTE:\n",
            "    conf-compute                Control and query confidential compute. \"nvidia-smi conf-compute -h\" for more information. \n",
            "\n",
            " GPU PERFORMANCE MONITORING: \n",
            "    gpm                         Control and query GPU performance monitoring unit. \"nvidia-smi gpm -h\" for more information. \n",
            "\n",
            " PCI:\n",
            "    pci                         Display device PCI information. \"nvidia-smi pci -h\" for more information.\n",
            "\n",
            " Power Smoothing:\n",
            "    power-smoothing             Control and query power smoothing information. \"nvidia-smi power-smoothing -h\" for more information.\n",
            "\n",
            " Power Profiles:\n",
            "    power-profiles              Control and query workload power profiles information. \"nvidia-smi power-profiles -h\" for more information.\n",
            "\n",
            " PRM:\n",
            "    prm                         Query GPU PRM registers. \"nvidia-smi prm -h\" for more information.\n",
            "\n",
            "Please see the nvidia-smi(1) manual page for more detailed information.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi -l 1 #Updates GPU statistics every 1 second, used for real-time monitoring\n",
        "\n"
      ],
      "metadata": {
        "id": "ilCPfunFsgd2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a82d4806-4dd9-447b-bf5e-2f64391adea6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Feb 15 17:48:58 2026       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 580.82.07              Driver Version: 580.82.07      CUDA Version: 13.0     |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P8             11W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "Sun Feb 15 17:48:59 2026       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 580.82.07              Driver Version: 580.82.07      CUDA Version: 13.0     |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P0             26W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "Sun Feb 15 17:49:01 2026       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 580.82.07              Driver Version: 580.82.07      CUDA Version: 13.0     |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P8             13W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "Sun Feb 15 17:49:02 2026       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 580.82.07              Driver Version: 580.82.07      CUDA Version: 13.0     |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P8             13W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "Sun Feb 15 17:49:03 2026       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 580.82.07              Driver Version: 580.82.07      CUDA Version: 13.0     |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P0             26W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "Sun Feb 15 17:49:04 2026       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 580.82.07              Driver Version: 580.82.07      CUDA Version: 13.0     |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P8             13W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "Sun Feb 15 17:49:05 2026       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 580.82.07              Driver Version: 580.82.07      CUDA Version: 13.0     |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P8             13W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "Sun Feb 15 17:49:06 2026       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 580.82.07              Driver Version: 580.82.07      CUDA Version: 13.0     |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P0             26W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "Sun Feb 15 17:49:07 2026       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 580.82.07              Driver Version: 580.82.07      CUDA Version: 13.0     |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P8             13W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "Sun Feb 15 17:49:09 2026       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 580.82.07              Driver Version: 580.82.07      CUDA Version: 13.0     |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P8             13W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "Sun Feb 15 17:49:10 2026       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 580.82.07              Driver Version: 580.82.07      CUDA Version: 13.0     |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P8             13W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "Sun Feb 15 17:49:11 2026       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 580.82.07              Driver Version: 580.82.07      CUDA Version: 13.0     |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P0             26W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q3.  Debug common CUDA errors (zero output, incorrect indexing, PTX errors)"
      ],
      "metadata": {
        "id": "96PAjr0LnT_B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer.\n",
        "\n",
        "Zero output causes-\n",
        "\n",
        "Program ends before GPU finishes → missing cudaDeviceSynchronize().\n",
        "\n",
        "Output computed on GPU but not copied back to host, etc"
      ],
      "metadata": {
        "id": "Y1naUGqHgl7x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile zero_fix.cu\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "__global__ void helloKernel() {\n",
        "    printf(\"Hello from GPU thread %d\\n\", threadIdx.x);\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    helloKernel<<<1, 4>>>();\n",
        "    cudaDeviceSynchronize();   // Fix: wait for GPU-- if not there then GPU output may not appear because the program ends before the kernel finishes.\n",
        "\n",
        "    printf(\"Hello from CPU\\n\");\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Me6mJ4MbgPIe",
        "outputId": "0b5cd956-3c75-4314-e8df-29c066f6e976"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing zero_fix.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 zero_fix.cu -o zero_fix && ./zero_fix"
      ],
      "metadata": {
        "id": "URYGM3jvnUGm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19799c9b-23b6-4c01-c41b-714aad67e737"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello from GPU thread 0\n",
            "Hello from GPU thread 1\n",
            "Hello from GPU thread 2\n",
            "Hello from GPU thread 3\n",
            "Hello from CPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Incorrect Indexing Error\n",
        "Problem\n",
        "\n",
        "Using only threadIdx.x ignores block number → wrong results for multiple blocks."
      ],
      "metadata": {
        "id": "XJw_Yn4Xi7Jr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile index_fix.cu\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "__global__ void printID() {\n",
        "    int id = blockIdx.x * blockDim.x + threadIdx.x; //  Wrong indexing-->int id = threadIdx.x;\n",
        "    printf(\"Thread id = %d\\n\", id);\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    printID<<<2, 4>>>();   // 8 total threads\n",
        "    cudaDeviceSynchronize();\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "EGvWCVz6iZfk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " PTX / Architecture Error\n",
        "Problem\n",
        "\n",
        "Compiled for wrong GPU architecture."
      ],
      "metadata": {
        "id": "ANUFiSANjBp9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile ptx_demo.cu\n",
        "#include <stdio.h>\n",
        "\n",
        "__global__ void testKernel() {\n",
        "    printf(\"GPU running correctly\\n\");\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    testKernel<<<1,1>>>();\n",
        "    cudaDeviceSynchronize();\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQlvaVRliZjK",
        "outputId": "3a532dbe-27ec-45a0-8d7b-b282e10ca507"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing ptx_demo.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_30 ptx_demo.cu -o ptx_demo ./ptx.demo //wrong compile --causes ptx error"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKM3tMpzjNp0",
        "outputId": "69804971-7957-4695-b2e5-6df60df35871"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc fatal   : Unsupported gpu architecture 'sm_30'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 ptx_demo.cu -o ptx_demo ./ptx_demo  //correct compile"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4NpCwDbdiZmx",
        "outputId": "80b9bf98-0cc9-4a6e-ea9d-3f229893ceb7"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc fatal   : Don't know what to do with './ptx_demo'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q4. Write a CUDA C/C++ program to demonstrate GPU kernel execution and thread indexing.\n",
        "a. Launch a CUDA kernel using: 1 block and 8 threads\n",
        "\n",
        "b. Each thread must print: Hello from GPU thread <global_thread_id>\n",
        "\n",
        "c. Compute the global thread ID using: global_thread_id = blockIdx.x * blockDim.x + threadIdx.x\n",
        "\n",
        "d. Clearly separate: Host code (CPU) & Device code (GPU kernel)"
      ],
      "metadata": {
        "id": "o5VF7qrUnUPu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile answer.cu\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "// ---------------Device code (GPU kernel)-------------------\n",
        "__global__ void helloKernel() {\n",
        "    int global_thread_id = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    printf(\"Hello from GPU thread %d\\n\", global_thread_id);\n",
        "}\n",
        "\n",
        "// ------------- Host code (CPU)---------------------------\n",
        "int main() {\n",
        "    helloKernel<<<1, 8>>>();\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    printf(\"Hello from CPU\\n\");\n",
        "    return 0;\n",
        "}\n",
        "\n"
      ],
      "metadata": {
        "id": "1WwV-JFMnUYE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba1094df-cdf0-4a05-f5e8-337f58618fc6"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting answer.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 answer.cu -o answer && ./answer"
      ],
      "metadata": {
        "id": "ivGn7XFNo5MH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bba00348-7d20-456b-e134-8bb8d49b10fd"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello from GPU thread 0\n",
            "Hello from GPU thread 1\n",
            "Hello from GPU thread 2\n",
            "Hello from GPU thread 3\n",
            "Hello from GPU thread 4\n",
            "Hello from GPU thread 5\n",
            "Hello from GPU thread 6\n",
            "Hello from GPU thread 7\n",
            "Hello from CPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q5. Write a CUDA program to demonstrate host and device memory separation.\n",
        "a. Create an integer array of size 5 on the host (CPU).\n",
        "\n",
        "b. Allocate corresponding memory on the device (GPU) using cudaMalloc().\n",
        "\n",
        "c. Copy data from host to device using cudaMemcpy().\n",
        "\n",
        "d. Launch a kernel where GPU threads print values from device memory.\n",
        "\n",
        "e. Copy the data back from device to host and print it on CPU."
      ],
      "metadata": {
        "id": "VMgZR5qKdiHK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile mem_separation.cu\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "// ---------- Device code (GPU) ----------\n",
        "__global__ void show(int *d) {\n",
        "    int i = threadIdx.x;              // 1 block only, so threadIdx.x is enough\n",
        "    printf(\"GPU: d[%d] = %d\\n\", i, d[i]);\n",
        "}\n",
        "\n",
        "// ---------- Host code (CPU) ----------\n",
        "int main() {\n",
        "    int h[5] = {10, 20, 30, 40, 50};\n",
        "    int *d;\n",
        "\n",
        "    cudaMalloc(&d, 5 * sizeof(int));\n",
        "    cudaMemcpy(d, h, 5 * sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "    show<<<1, 5>>>(d);\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    cudaMemcpy(h, d, 5 * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    printf(\"\\nCPU after copy back:\\n\");\n",
        "    for (int i = 0; i < 5; i++) {\n",
        "        printf(\"CPU: h[%d] = %d\\n\", i, h[i]);\n",
        "    }\n",
        "\n",
        "    cudaFree(d);\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "9eU4B9QTo5PO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ebe7bf0-9b31-4594-b4d0-f7c11ec47d8d"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting mem_separation.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 mem_separation.cu -o mem_separation"
      ],
      "metadata": {
        "id": "VY8KR26ko5R8"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./mem_separation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sen8eZKcd_IM",
        "outputId": "5db034ec-96bc-42fe-ebfe-42ca572ec254"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU: d[0] = 10\n",
            "GPU: d[1] = 20\n",
            "GPU: d[2] = 30\n",
            "GPU: d[3] = 40\n",
            "GPU: d[4] = 50\n",
            "\n",
            "CPU after copy back:\n",
            "CPU: h[0] = 10\n",
            "CPU: h[1] = 20\n",
            "CPU: h[2] = 30\n",
            "CPU: h[3] = 40\n",
            "CPU: h[4] = 50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q6. Compare CPU times of List/tuple with Numpy arrays."
      ],
      "metadata": {
        "id": "uWmQV9a1eUFU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer.\n",
        "\n",
        "NumPy arrays give much lower CPU time than list/tuple for large numerical computations because NumPy uses vectorized, compiled operations on contiguous memory, whereas list/tuple computations rely on slow Python-level loops."
      ],
      "metadata": {
        "id": "DI5CBNSGeoWk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "\n",
        "N = 5_000_000\n",
        "\n",
        "lst = list(range(N))\n",
        "tup = tuple(range(N))\n",
        "arr = np.arange(N)\n",
        "\n",
        "# ---- 1) Sum comparison ----\n",
        "start = time.time()\n",
        "s1 = sum(lst)\n",
        "t_list_sum = time.time() - start\n",
        "\n",
        "start = time.time()\n",
        "s2 = sum(tup)\n",
        "t_tuple_sum = time.time() - start\n",
        "\n",
        "start = time.time()\n",
        "s3 = np.sum(arr)\n",
        "t_numpy_sum = time.time() - start\n",
        "\n",
        "print(\"SUM timings (seconds)\")\n",
        "print(\"List :\", t_list_sum)\n",
        "print(\"Tuple:\", t_tuple_sum)\n",
        "print(\"NumPy:\", t_numpy_sum)\n",
        "\n",
        "# ---- 2) Element-wise operation: x*2 ----\n",
        "start = time.time()\n",
        "lst2 = [x * 2 for x in lst]\n",
        "t_list_op = time.time() - start\n",
        "\n",
        "start = time.time()\n",
        "arr2 = arr * 2\n",
        "t_numpy_op = time.time() - start\n",
        "\n",
        "print(\"\\nELEMENT-WISE x*2 timings (seconds)\")\n",
        "print(\"List  :\", t_list_op)\n",
        "print(\"NumPy :\", t_numpy_op)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVAk5mqueUSH",
        "outputId": "f86613de-b284-44ca-d397-9d616ec64945"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SUM timings (seconds)\n",
            "List : 0.04225659370422363\n",
            "Tuple: 0.03932380676269531\n",
            "NumPy: 0.0031175613403320312\n",
            "\n",
            "ELEMENT-WISE x*2 timings (seconds)\n",
            "List  : 0.19726777076721191\n",
            "NumPy : 0.013377189636230469\n"
          ]
        }
      ]
    }
  ]
}